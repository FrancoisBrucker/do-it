
<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <title>Bibliothèques Python pour la Data Science (Partie 2/2) : Seaborn, Scikit Learn</title>

        <link href="/do-it/assets/node_modules/prismjs/themes/prism-solarizedlight.min.css" rel="stylesheet">
        <link href="/do-it/assets/node_modules/prismjs/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet">

        <link href="/do-it/assets/stylesheets/main.css" rel="stylesheet">
    </head>
    <body>
        <script>
        window.MathJax = {
            tex: {
            inlineMath: [
                [
                '$', '$'
                ],
                [
                '\\(', '\\)'
                ]
            ]
            },
            svg: {
            fontCache: 'global'
            }
        };
        </script>
        <script type="text/javascript" id="MathJax-script" src="/do-it/assets/node_modules/mathjax/es5/tex-svg-full.js"></script>

        <header class="border-b-2 border-gray-200 mb-4">
        <div class="max-w-[1000px] mx-auto px-4">
            <div class="min-h-[50px] flex justify-between items-center">
                <a class="mx-2" href="/do-it/">Home</a>
                <div class="flex items-center gap-4 sm:gap-6 ">
                    <a class="" href="/do-it/cs">CS</a>
                    <a class="" href="/do-it/pok">POK</a>
                    <a class="" href="/do-it/mon">MON</a>
                    <a class="" href="/do-it/projets">Projets</a>
                    <a class="hidden sm:block" href="/do-it/promos">Promos</a>
                    <a href="/do-it/search">
                        <svg class="h-5 aspect-square" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path>
                        </svg>
                    </a>
                    <a class="hidden sm:block" href="https://github.com/FrancoisBrucker/do-it" target="_blank">
                        <svg class="h-5 aspect-square" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg>
                    </a>
                </div>
            </div>
        </div>
        </header>

        <main class="max-w-[1000px] mx-auto px-4" data-pagefind-body="">
            
<article class="relative">
<h1 class="mb-1">Bibliothèques Python pour la Data Science (Partie 2/2) : Seaborn, Scikit Learn</h1>
<div class="mb-4">
    
        <div class="px-4 flex flex-wrap items-center">
            
                <div class="font-bold">Tags : </div>
            
            <ul class="flex flex-wrap overflow-auto not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Tags">
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">MON</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">2023-2024</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">temps 2</li>
                

            </ul>
            
            
            <div class="hidden" data-pagefind-meta="Type">
                
                    
                
                    
                
                    
                
            </div>
        </div>
    

    
        <div class="px-4 flex flex-wrap items-center">
            <div class="font-bold">Auteurs : </div>
            <ul class="flex flex-wrap not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Auteurs">
                
                    <li class="bg-blue-200 rounded-full px-2" data-pagefind-filter="Auteurs">Alexandre Beyaert</li>
                
            </ul>
        </div>
    

    
</div>

        <p class="mb-4 text-lg">

                Un MON traitant de l'utilisation des bibliothèques Python pour la Data Science.

        </p>



    
<div class="quote relative  py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-purple-500 bg-purple-100">
<svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 text-purple-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
  <path stroke-linecap="round" stroke-linejoin="round" d="M5 19a2 2 0 01-2-2V7a2 2 0 012-2h4l2 2h4a2 2 0 012 2v1M5 19h14a2 2 0 002-2v-5a2 2 0 00-2-2H9a2 2 0 00-2 2v5a2 2 0 01-2 2z"></path>
</svg>
<div class="pl-8 mr-8">

<a href="/do-it/promos/">Promotions</a><span class="px-1">/</span><a href="/do-it/promos/2023-2024/">2023-2024</a><span class="px-1">/</span><a href="/do-it/promos/2023-2024/Beyaert-Alexandre/">Alexandre BEYAERT</a><span class="px-1">/</span><a href="/do-it/promos/2023-2024/Beyaert-Alexandre/mon/">MON de Alexandre Beyaert</a><span class="px-1">/</span><a href="/do-it/promos/2023-2024/Beyaert-Alexandre/mon/temps-2.2/">Bibliothèques Python pour la Data Science (Partie 2/2) : Seaborn, Scikit Learn</a>

</div></div>




<div class="quote relative  py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-pink-500 bg-pink-100">
<svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 text-pink-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
  <path stroke-linecap="round" stroke-linejoin="round" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.747 0 3.332.477 4.5 1.253v13C19.832 18.477 18.247 18 16.5 18c-1.746 0-3.332.477-4.5 1.253"></path>
</svg>
<div class="pl-8 mr-8">
<p><strong>Niveau :</strong> Moyen
<strong>Prérequis :</strong> Bases en Python</p>
</div></div>
<h2>Sommaire</h2>
<ol>
<li>Introduction</li>
<li>Bibliothèque Seaborn</li>
<li>Bibliothèque Scikit Learn</li>
<li>Application : combinaison des bibliothèques</li>
<li>Conclusion</li>
<li>Bibliographie</li>
</ol>
<h2>1. Introduction</h2>
<p>La vocation de ce MON est d'introduire de façon non exhaustive aux bibliothèques python utiles pour la DataScience.
Ce second MON introduit aux bibliothèques Seaborn et Scikit Leanr qui servent respectivement à la <strong>visualisation des données et au Machine Learning.</strong></p>
<p>Le MON 2.2 est une suite du <a href="https://francoisbrucker.github.io/do-it/promos/2023-2024/Beyaert-Alexandre/mon/temps-2.1/">MON 2.1</a> qui lui introduit les bibliothèques NumPy, Matplotlib et Pandas.</p>
<h2>2. Bibliothèque Seaborn</h2>
<pre class="language-python"><code class="language-python"><span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns</code></pre>
<p>La bibliothèque Seaborn va permettre d'obtenir de la <strong>visualisation avancée</strong> en comparaison à Matplotlib et ce en simplifiant les lignes de code.</p>
<p>Reprenons l'exemple du <strong>dataset iris</strong> <em>(cf MON 2.1)</em>.
En lisant ce dataset sous forme de dataframe pandas, il va être possible en une seule ligne de code de produire une figure montrant toutes les différentes relations entre nos différentes variables.</p>
<pre class="language-python"><code class="language-python">chemin <span class="token operator">=</span> <span class="token string">'C:\MOOC_Data_Sciences\Machine_Learnia\iris.csv'</span>
iris <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>chemin<span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>pairplot<span class="token punctuation">(</span>iris<span class="token punctuation">)</span></code></pre>
<p><img src="pairplot.png" alt="Figure des relations entre variables du dataset iris"></p>
<p>Pour aller plus loin, il va même être possible d'analyser les sépales et pétales par variété de fleur grâce à l'ajout d'un seul paramètre.</p>
<pre class="language-python"><code class="language-python">sns<span class="token punctuation">.</span>pairplot<span class="token punctuation">(</span>iris<span class="token punctuation">,</span> hue <span class="token operator">=</span> <span class="token string">'variety'</span><span class="token punctuation">)</span></code></pre>
<p><img src="pairplot_variety.png" alt="Distinction par variété"></p>
<p>Les possibilités de seaborn sont multiples, <a href="https://seaborn.pydata.org/">la documentation officielle</a> répertorie les différents graphiques réalisables en fonction des besoins :</p>
<ul>
<li>distributions</li>
<li>regressions</li>
<li>catégories...</li>
</ul>
<p>Et ces possibilités ont presque toujours la même structure : <strong>sns.fonction(x, y, data, hue, size, style)</strong></p>
<p>À titre d'exemple, reprenons désormais <strong>le dataset titanic.</strong> Il va être possible d'étudier la répartition des âges des passagers en fonction de leur classe et de leur sexe, sous forme de categorical plot ou de box plot.</p>
<pre class="language-python"><code class="language-python">titanic <span class="token operator">=</span> sns<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">'titanic'</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>catplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'age'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>titanic<span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token string">'sex'</span><span class="token punctuation">)</span>
sns<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'age'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>titanic<span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token string">'sex'</span><span class="token punctuation">)</span></code></pre>
<p><img src="catplot_titanic.png" alt="Répartition des passagers"></p>
<p><img src="boxplot_titanic.png" alt="Répartition des passagers"></p>
<p>On va également pouvoir visualiser la relation entre 2 distributions.</p>
<pre class="language-python"><code class="language-python">sns<span class="token punctuation">.</span>jointplot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token string">'age'</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'fare'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>titanic<span class="token punctuation">,</span> kind<span class="token operator">=</span><span class="token string">'hex'</span><span class="token punctuation">)</span></code></pre>
<p><img src="jointplot_titanic.png" alt="Tarif en fonction de l'âge"></p>
<p>Ou encore visualiser les matrices de corrélation sous forme de heatmap.</p>
<p><strong>NB :</strong> Attention, il s'avère au préalable nécessaire de supprimer les colonnes contenant autre chose que des int ou float ou de convertir des colonnes. <em>(cf partie 3.3 Préparation des données)</em></p>
<pre class="language-python"><code class="language-python">sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>titanic<span class="token punctuation">.</span>corr<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p><img src="heatmap_titanic.png" alt="Heatmap de corrélation"></p>
<h2>3. Bibliothèque Scikit Learn</h2>
<p>La bibliothèque Scikit Learn va permettre d'<strong>effectuer du Machine Learning.</strong></p>
<p>C'est cette bibliothèque qui répertorie toutes les méthodes d'apprentissage et prêtes à l'emploi. <a href="https://scikit-learn.org/stable/#">La documentation Scikit-Learn</a> va alors être très utile. Elle répertorie ces différentes méthodes : classification, régression, clustering... et explique leur fonctionnement. Ainsi, il n'y aura plus qu'à appeler les différentes fonctions déjà codées en python orienté objet pour effectuer du Machine Learning.</p>
<p>Les programmes utilisant Sckit Learn auront tous le même schéma :</p>
<ul>
<li>Sélection du modèle et précision de ses hyperpramètres : <strong>model = LinearRegression(...)</strong></li>
<li>Entraînement du modèle : <strong>model.fit(X, Y)</strong></li>
<li>Évaluation du modèle : <strong>model.score(X, Y)</strong></li>
<li>Utilisation du modèle : <strong>model.predict(X)</strong></li>
</ul>
<h3>3.1 Régression</h3>
<p>Voici ci-dessous une façon de réaliser une régression linéaire en suivante le schéma <strong>&quot;choix du modèle - entraînement - évaluation - utilisation&quot;</strong>.</p>
<pre class="language-python"><code class="language-python"><span class="token comment">## Création des données</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">## Modèle</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression

model <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span> <span class="token comment">## renvoie le coefficient de détermination</span>
predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment">## renvoie un tableau Numpy des prédictions</span>

<span class="token comment">## Visualisation</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X<span class="token punctuation">,</span>predictions<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span></code></pre>
<p><img src="regression_lineaire.png" alt="Régression linéaire"></p>
<p>Pour s'adapter à un cas où la relation entre les données ne serait plus linéaire, il ne suffira que de changer de modèle. Nous pourrions envisager le modèle SVR <em>(Support Vector Regression)</em>.</p>
<p><strong>NB :</strong> En regardant la <a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html">documentation de ce modèle</a>, on comprend que pour ce modèle, seuls 2 hyperparamètres peuvent être ajustés :</p>
<ul>
<li>C : paramètre de régularisation. Il détermine la marge d'erreur tolérée par le modèle. (attention au surapprentissage si celui-ci est choisi trop grand)</li>
<li>epsilon : l'erreur par rapport à la prédiction, comme en prépa lors de la détermination de limites, il s'agit du tunnel de tolérance autour d'une courbe. Plus epsilon est grand, plus le modèle est tolérant aux erreurs.</li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Y <span class="token operator">=</span> X<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">## Modèle</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVR
model <span class="token operator">=</span> SVR<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></code></pre>
<p>Et voici notre nouvelle régression.</p>
<p><img src="SVR.png" alt="Régression SVR"></p>
<h3>3.2 Classification</h3>
<p>Basons nous une nouvelle fois le dataset titanic pour effectuer de la classification et ainsi déterminer les chances de survie d'un passager.</p>
<p>Un modèle approprié pourrait être le <a href="https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification">KNeighborsClassifier</a>. Celui-ci va analyser les K plus proches voisins d'un élément et tirer la classification la plus probable qui en ressort.</p>
<p>Commençons par <strong>importer</strong> et <strong>filtrer</strong> le dataset.</p>
<pre class="language-python"><code class="language-python">titanic <span class="token operator">=</span> sns<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">'titanic'</span><span class="token punctuation">)</span>

titanic <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">,</span> <span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
titanic<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
titanic<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'male'</span><span class="token punctuation">,</span> <span class="token string">'female'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre>
<p>Puis <strong>implémentons</strong> le modèle.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier

model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>

Y <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span></code></pre>
<p>Le score qui en ressort est alors de 84% : les prédictions du modèle sont bonnes dans 84% des cas et la fonction model.predict(X) renvoie un tableau de 0 et de 1 indiquant les passagers qui survivraient.</p>
<p>Pour aller plus loin, créons une fonction permettant de déterminer si un individu lambda aurait survécu et avec quelle probabilité.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">survie</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> pclass<span class="token punctuation">,</span> sex<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>pclass<span class="token punctuation">,</span> sex<span class="token punctuation">,</span> age<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>Ainsi en testant la fonction sur moi : pclass=3, sex=0, age=24 ; le modèle prédit que je ne survivrai pas avec une probabilité de 80%.</p>
<p>En suivant ces précédentes manipulations, on biaise toutefois le résultat puisque l'on teste notre modèle sur les données d'entraînement. En pratique, il est <strong>nécessaire de diviser notre dataset en données d'entraînement et données de test.</strong></p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> Y_train<span class="token punctuation">,</span> Y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># On choisit le nombre de plus proches voisins</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train score:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test score:'</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>En sortie, on observe que sur les données d'entraînement l'algorithme est fiable à 89% contre 79% pour les données de test.</p>
<p>Puisque l'on choisit le nombre de plus proches voisins, vient alors la question de l'optimisation de cet hyperparamètre et des performances de l'algorithme.</p>
<p>Il peut être intéressant de diviser notre dataset en plusieurs parties dont l'une d'entre elle sert à la validation. En réitérant cette étape plusieurs fois, nous pourrions alors déterminer la meilleure façon d'optimiser l'algorithme.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> validation_curve

model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
k <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span> <span class="token comment"># tableau Numpy répertoriant le nombre de plus proches voisins que nous allons tester</span>

train_score<span class="token punctuation">,</span> val_score <span class="token operator">=</span> validation_curve<span class="token punctuation">(</span>model<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">,</span> param_name<span class="token operator">=</span><span class="token string">'n_neighbors'</span><span class="token punctuation">,</span> param_range<span class="token operator">=</span>k<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment"># on teste le paramètre n_neighbors sur le tableau k et l'on divise nos données en 5 parties (cross validation)</span>

train_score<span class="token punctuation">.</span>shape <span class="token comment"># train_score est alors un tableau à 49 lignes (les itérations du tableau k) et à 5 colonnes issues de la cross validation</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>k<span class="token punctuation">,</span> val_score<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'validation'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>k<span class="token punctuation">,</span> train_score<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'n_neighbors'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'score'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<p><img src="cross_validation.png" alt="Recherche du meilleur nombre de plus proches voisins"></p>
<p>L'écart entre la courbe train et celle validation est très important lorsqu'on ne sélectionne qu'un seul plus proche voisin, il y a de l'<strong>overfitting</strong>. Le modèle essaye trop de se rapprocher des données qu'il apprend et en déforme la réalité. Cet écart diminue plus le nombre de plus proches voisins augmente. Cependant, lorsque l'on choisit trop de plus proches voisins, la performance de la courbe validation diminue puisque certains plus proches voisins sont en réalité éloignés de l'élément à analyser.</p>
<p><strong>Une dizaine de plus proches voisins semble être la solution la plus appropriée</strong>, il s'agit de celle maximisant la précision des données de validation et minimisant l'écart avec le train.</p>
<p>Vérifions désormais cette supposition grâce aux fonctions de la bibliothèque Scikit-Learn.</p>
<p>Le module <strong>GridSearchCV</strong> est capable de donner le meilleur score atteignable pour un modèle et les paramètres associés.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV

param_grid <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'metric'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'euclidiean'</span><span class="token punctuation">,</span> <span class="token string">'manhattan'</span><span class="token punctuation">]</span><span class="token punctuation">}</span> <span class="token comment"># on crée un dictionnaire avec les paramètres à tester : n_neigbors et la mesure de distance parmi différentes possibilités</span>

grid <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> param_grid<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

grid<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span> <span class="token comment"># on entraîne la grille comme précédemment</span>

<span class="token comment"># La grille est prête à renvoyer les différents éléments par exemple</span>
grid<span class="token punctuation">.</span>best_score_ <span class="token comment"># renvoie le meilleur score atteignable, dans notre cas 77%</span>

grid<span class="token punctuation">.</span>best_params_ <span class="token comment"># renvoie les meilleurs paramètres, dans notre cas 9 plus proches voisins (ce qui confirme la 10aine observée précédemment) et la distance manhattan</span></code></pre>
<p>Si on le souhaite, il va ainsi être possible de régler notre modèle avec ces paramètres optimums et d'observer la matrice de confusion : la matrice retournant le nombre de bonnes réponses et d'erreurs.</p>
<pre class="language-python"><code class="language-python">model <span class="token operator">=</span> grid<span class="token punctuation">.</span>best_estimator_

model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span> <span class="token comment"># renvoie le 71% précédent</span>

confusion_matrix<span class="token punctuation">(</span>Y_test<span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># renvoie la matrice ci-dessous</span>
<span class="token comment">#array([[65, 20],</span>
<span class="token comment">#       [21, 37]], dtype=int64)</span>
<span class="token comment"># 65 survivants ont bien été trouvé par l'algorithme mais 20 d'entre eux sont manquants et ont été classés comme morts</span>
<span class="token comment"># à l'inverse, 37 morts ont bien été trouvé mais 21 d'entre eux ont été prédits comme survivants alors qu'ils sont morts</span>

<span class="token comment"># Nous pouvons retrouver notre 71% de performances en vérifiant le rapport (bonnes prédictions / nombre de prédictions)</span>
<span class="token comment"># (65 + 37)/(65 + 20 + 21 + 37) = 71%</span></code></pre>
<h3>3.3 Préparation des données</h3>
<h4>3.3.1 Encodage</h4>
<p>Je l'ai déjà mentionné précédemment, avant de pouvoir effectuer du machine learning, j'effectue un pré-traitement des données. Par exemple, pour effectuer des calculs (régressions, classifications...) il est très souvent nécessaire de travailler avec des valeurs numériques. Certaines valeurs vont alors poser problèmes :</p>
<ul>
<li>les données manquantes 'NaN'</li>
<li>les chaînes de caractères telles que 'male' ou 'female' dans la colonne 'sex' du dataset titanic</li>
</ul>
<p>Dans le premier cas, un simple usage de la fonction <strong>dropna()</strong> résoudra notre problème. Pour ce qui est du second cas, il sera nécessaire d'effectuer de l'<strong>encodage</strong>.</p>
<p>2 types d'encodages sont envisageables :
<strong>- l'encodage Ordinal :</strong> il associe chaque catégorie d'une variable à une valeur décimale unique</p>
<table>
<thead>
<tr>
<th>chat</th>
<th>chien</th>
<th>oiseau</th>
<th>chien</th>
<th>chat</th>
<th>lion</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>2</td>
</tr>
</tbody>
</table>
<p>Lorsque nous avons une simple liste, la fonction à utiliser sera alors <strong>LabelEncoder()</strong>.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder

y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'chat'</span><span class="token punctuation">,</span> <span class="token string">'chien'</span><span class="token punctuation">,</span> <span class="token string">'oiseau'</span><span class="token punctuation">,</span> <span class="token string">'chien'</span><span class="token punctuation">,</span> <span class="token string">'chat'</span><span class="token punctuation">,</span> <span class="token string">'lion'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

encoder <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># création de l'objet</span>

<span class="token comment"># Méthode 1</span>
encoder<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># développement de l'encoder</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoder<span class="token punctuation">.</span>classes_<span class="token punctuation">)</span> <span class="token comment"># renvoie les différentes classes existantes</span>
<span class="token comment"># ['chat' 'chien' 'lion' 'oiseau']</span>
encoder<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># appliquer la transformation</span>
<span class="token comment"># array([0, 1, 3, 1, 0, 2])</span>

<span class="token comment"># Méthode 2</span>
encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># fais tout en 1</span>
<span class="token comment"># array([0, 1, 3, 1, 0, 2])</span></code></pre>
<p>À l'inverse, on peut retrouver ces chaînes de caractère à partir des nombres.</p>
<pre class="language-python"><code class="language-python">encoder<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># renvoie : array(['oiseau', 'lion', 'oiseau', 'chat', 'chien', 'oiseau'], dtype='&lt;U6')</span></code></pre>
<p>Dans le cas d'un tableau à plusieurs variables, il faudra opter pour la fonction <strong>OrdinalEncoder()</strong>.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OrdinalEncoder

X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Chat'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Chien'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Chat'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Oiseau'</span><span class="token punctuation">,</span> <span class="token string">'Plumes'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

encoder <span class="token operator">=</span> OrdinalEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># Renvoie le tableau ci-dessous</span>

array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Le problème de l'encodage ordinal est qu'il <strong>crée un ordre</strong> 0 &lt; 1 &lt; 2... et cet ordre risque de pénaliser des modèles de Machine Learning. Pour y remédier, il faudra opter pour l'encodage One Hot.</p>
<p><strong>- L'encodage One Hot :</strong> permet d'éviter l'ordonancement, il va représenter chacune des valeurs sous forme de vecteurs, empêchant ainsi les comparaisons.</p>
<p>Pour une simple liste, il faut utiliser <strong>LabelBinarizer()</strong>.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelBinarizer

y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'chat'</span><span class="token punctuation">,</span> <span class="token string">'chien'</span><span class="token punctuation">,</span> <span class="token string">'oiseau'</span><span class="token punctuation">,</span> <span class="token string">'chien'</span><span class="token punctuation">,</span> <span class="token string">'chat'</span><span class="token punctuation">,</span> <span class="token string">'lion'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

encoder <span class="token operator">=</span> LabelBinarizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># Renvoie le tableau ci-dessous</span>

array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Et pour un tableau, <strong>OneHotEncoder()</strong>.</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoder

X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Chat'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Chien'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Chat'</span><span class="token punctuation">,</span> <span class="token string">'Poils'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token string">'Oiseau'</span><span class="token punctuation">,</span> <span class="token string">'Plumes'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

encoder <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># Renvoie un tableau compressé ci-dessous</span>
<span class="token operator">&lt;</span>4x5 sparse matrix of <span class="token builtin">type</span> <span class="token string">'&lt;class '</span>numpy<span class="token punctuation">.</span>float64<span class="token string">'>'</span>
	<span class="token keyword">with</span> <span class="token number">8</span> stored elements <span class="token keyword">in</span> Compressed Sparse Row <span class="token builtin">format</span><span class="token operator">></span></code></pre>
<h4>3.3.2 Normalisation</h4>
<p>La normalisation est également une étape très importante du pré-traitement.
Elle va notamment permettre à l'algorithme de converger plus facilement vers sa valeur finale.</p>
<p>3 types de normalisation sont principalement utilisés :</p>
<ul>
<li>MinMax : la plage de données initiale va être rapportée à l'intervalle [0, 1]</li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler

X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

scaler <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token comment"># Renvoie le tableau ci-dessous</span>

array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token number">1.</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<ul>
<li>Standardisation : les données seront normalisées de sorte à obtenir une moyenne nulle et un écart type égal à 1</li>
</ul>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9258201</span> <span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.46291005</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
       <span class="token punctuation">[</span> <span class="token number">1.38873015</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p>Le problème de ces 2 premières techniques est qu'elles sont très sensibles aux valeurs aberrantes.</p>
<ul>
<li>RobustScaler : chaque donnée sera soustraite à la médiane le tout divisé par l'interquartile (X-mediane)/(Q3-Q1)</li>
</ul>
<h2>4. Application : combinaison des bibliothèques</h2>
<p>Pour terminer ce MON, je vous propose d'effectuer un algorithme combinant nos différentes bibliothèques et incluant un  pipeline complet de Machine Learning &quot;pré-traitement - modèle - entraînement - évaluation - visualisation&quot; afin de prédire la survie des passagers du Titanic.</p>
<p>Le score sera ensuite comparé à celui obtenu sans pré-traitement.</p>
<pre class="language-python"><code class="language-python"><span class="token comment"># imports</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> make_pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix

<span class="token comment"># import du dataset</span>
titanic <span class="token operator">=</span> sns<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">'titanic'</span><span class="token punctuation">)</span> 

<span class="token comment"># sélection des colonnes et supression des NaN</span>
titanic <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">,</span> <span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> 
titanic<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

Y <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment"># encodage de la colonne 'sex'</span>
encoder <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
X<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># division en test, train</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> Y_train<span class="token punctuation">,</span> Y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

<span class="token comment"># choix du modèle, sous forme d'un pipeline pour appliquer les mêmes opérations au train et au test</span>
model <span class="token operator">=</span> make_pipeline<span class="token punctuation">(</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

param <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'kneighborsclassifier__n_neighbors'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token comment"># création de la grille de recherche</span>
grid <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>model<span class="token punctuation">,</span> param_grid<span class="token operator">=</span>param<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token comment"># entraînement</span>
grid<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>

<span class="token comment"># résultats</span>
grid<span class="token punctuation">.</span>best_params_

grid<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span>

<span class="token comment"># calcul de la matrice de confusion</span>
Y_pred <span class="token operator">=</span> grid<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
conf_matrix <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>Y_test<span class="token punctuation">,</span> Y_pred<span class="token punctuation">)</span>

<span class="token comment"># affichage de la matrice de confusion</span>
sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>conf_matrix<span class="token punctuation">,</span> annot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> fmt<span class="token operator">=</span><span class="token string">'d'</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'Blues'</span><span class="token punctuation">,</span> cbar<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
            xticklabels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Not Survived'</span><span class="token punctuation">,</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> yticklabels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Not Survived'</span><span class="token punctuation">,</span> <span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p><img src="combinaison.png" alt="Matrice de confusion"></p>
<p>On remarque ainsi que la performance est de 81%, alors que pour un modèle sans pré-traitement :</p>
<pre class="language-python"><code class="language-python">titanic <span class="token operator">=</span> sns<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">'titanic'</span><span class="token punctuation">)</span> <span class="token comment"># import du dataset</span>

titanic <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">,</span> <span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> 
titanic<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

Y <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token string">'survived'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> titanic<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'pclass'</span><span class="token punctuation">,</span> <span class="token string">'sex'</span><span class="token punctuation">,</span> <span class="token string">'age'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

encoder <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
X<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span> <span class="token operator">=</span> encoder<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'sex'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> Y_train<span class="token punctuation">,</span> Y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

model <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span></code></pre>
<p>La performance est de 74% soit une amélioration de la performance de (81-74)/74 = 8% avec les simples opérations de pré-traitement.</p>
<h2>5. Conclusion</h2>
<h4>Répartition du temps</h4>
<table>
<thead>
<tr>
<th>Timing</th>
<th>Seaborn</th>
<th>Sklearn modèle</th>
<th>Sklearn pré-traitement</th>
<th>Combinaison des bibliothèques</th>
</tr>
</thead>
<tbody>
<tr>
<td>Temps prévu (en heures)</td>
<td>2</td>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>Temps dédié (en heures)</td>
<td>2</td>
<td>4</td>
<td>2</td>
<td>2</td>
</tr>
</tbody>
</table>
<h2>6. Bibliographie</h2>
<p><a href="https://seaborn.pydata.org/">Documentation Seaborn</a>
<a href="https://scikit-learn.org/stable/#">Documentation Scikit Learn</a>
<a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html">Choisir le bon estimateur</a>
<a href="https://www.youtube.com/playlist?list=PLO_fdPEVlfKqMDNmCFzQISI2H_nJcEDJq">Chaine YouTube Machine Learnia</a></p>


</article>

        </main>


        <footer class="min-h-[50px] border-t-2 border-gray-200 mt-4">
            <div class="max-w-[1000px] mx-auto px-4">
                <div class="min-h-[50px] flex justify-center items-center">
                    <p class="text-center">
                        <span style="font-family: Consolas, sans-serif;">Do_<span style="color: #4a86e8">It</span></span> : Développent et Organisation en IT
                    </p>
                </div>
            </div>
        </footer>

        <script>
        MathJax
            .startup
            .document
            .getMathItemsWithin(document.body);
        </script>
        <script src="/do-it/assets/node_modules/prismjs/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>
    </body>
</html>
