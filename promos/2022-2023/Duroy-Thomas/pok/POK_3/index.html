
<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <title>POK 3: Analyse de sentiments avec PyTorch</title>

        <link href="/do-it/assets/node_modules/prismjs/themes/prism-solarizedlight.min.css" rel="stylesheet">
        <link href="/do-it/assets/node_modules/prismjs/plugins/line-numbers/prism-line-numbers.min.css" rel="stylesheet">

        <link href="/do-it/assets/stylesheets/main.css" rel="stylesheet">
    </head>
    <body>
        <script>
        window.MathJax = {
            tex: {
            inlineMath: [
                [
                '$', '$'
                ],
                [
                '\\(', '\\)'
                ]
            ]
            },
            svg: {
            fontCache: 'global'
            }
        };
        </script>
        <script type="text/javascript" id="MathJax-script" src="/do-it/assets/node_modules/mathjax/es5/tex-svg-full.js"></script>

        <header class="border-b-2 border-gray-200 mb-4">
        <div class="max-w-[1000px] mx-auto px-4">
            <div class="min-h-[50px] flex justify-between items-center">
                <a class="mx-2" href="/do-it/">Home</a>
                <div class="flex items-center gap-4 sm:gap-6 ">
                    <a class="" href="/do-it/cs">CS</a>
                    <a class="" href="/do-it/pok">POK</a>
                    <a class="" href="/do-it/mon">MON</a>
                    <a class="" href="/do-it/projets">Projets</a>
                    <a class="hidden sm:block" href="/do-it/promos">Promos</a>
                    <a href="/do-it/search">
                        <svg class="h-5 aspect-square" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"></path>
                        </svg>
                    </a>
                    <a class="hidden sm:block" href="https://github.com/FrancoisBrucker/do-it" target="_blank">
                        <svg class="h-5 aspect-square" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg>
                    </a>
                </div>
            </div>
        </div>
        </header>

        <main class="max-w-[1000px] mx-auto px-4" data-pagefind-body="">
            
<article class="relative">
<h1 class="mb-1">POK 3: Analyse de sentiments avec PyTorch</h1>
<div class="mb-4">
    
        <div class="px-4 flex flex-wrap items-center">
            
                <div class="font-bold">Tags : </div>
            
            <ul class="flex flex-wrap overflow-auto not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Tags">
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">POK</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">2022-2023</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">temps 3</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">AI</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">Data</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">Réseau de neurones</li>
                
                    <li class="bg-yellow-200 rounded-full px-2" data-pagefind-filter="Tags">NLP</li>
                

            </ul>
            
            
            <div class="hidden" data-pagefind-meta="Type">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </div>
        </div>
    

    
        <div class="px-4 flex flex-wrap items-center">
            <div class="font-bold">Auteurs : </div>
            <ul class="flex flex-wrap not-prose list-none my-1 mx-0 px-1 gap-1" data-pagefind-meta="Auteurs">
                
                    <li class="bg-blue-200 rounded-full px-2" data-pagefind-filter="Auteurs">Thomas Duroy</li>
                
            </ul>
        </div>
    

    
</div>



    
<div class="quote relative  py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-purple-500 bg-purple-100">
<svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 text-purple-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
  <path stroke-linecap="round" stroke-linejoin="round" d="M5 19a2 2 0 01-2-2V7a2 2 0 012-2h4l2 2h4a2 2 0 012 2v1M5 19h14a2 2 0 002-2v-5a2 2 0 00-2-2H9a2 2 0 00-2 2v5a2 2 0 01-2 2z"></path>
</svg>
<div class="pl-8 mr-8">

<a href="/do-it/promos/">Promotions</a><span class="px-1">/</span><a href="/do-it/promos/2022-2023/">2022-2023</a><span class="px-1">/</span><a href="/do-it/promos/2022-2023/Duroy-Thomas/">Thomas Duroy</a><span class="px-1">/</span><a href="/do-it/promos/2022-2023/Duroy-Thomas/pok/">POKs de Thomas </a><span class="px-1">/</span><a href="/do-it/promos/2022-2023/Duroy-Thomas/pok/POK_3/">POK 3: Analyse de sentiments avec PyTorch</a>

</div></div>




<h3>But : Analyse de sentiments dans le langage naturel à l'aide d'un réseau de neurone PyTorch</h3>
<p>Ce projet se concentre sur l'utilisation de PyTorch, une bibliothèque de deep learning open-source, pour former un réseau de neurones capable de classifier des textes selon leur sentiment. Le but est de récupérer les retours et commentaires d'utilisateurs concernant un topic (film, série, etc) et d'en extraire une tendance générale et prédictive.</p>
<h2>Plan du POK</h2>
<ol>
<li>
<p>Choix de la base de donnée</p>
</li>
<li>
<p>Pré-traitement des données</p>
</li>
<li>
<p>Choix et constructions du modèle de réseau de neurone</p>
</li>
<li>
<p>Entraînement, évaluation et réglage</p>
</li>
<li>
<p>Mise à l'épreuve en conditions réelle</p>
</li>
</ol>
<h2>Sprint 1</h2>
<ul>
<li>
<p>Premières recherches [x]</p>
</li>
<li>
<p>Choix d'un modèle type [x]</p>
</li>
<li>
<p>Installation de PyTorch, CUDA et autres librairies nécessaire [X]</p>
</li>
<li>
<p>Prise en main de PyTorch (tensor, construction de réseau) [~]</p>
</li>
<li>
<p>Récupération des données [~]</p>
</li>
</ul>
<p>Pour le prochain sprint:</p>
<ul>
<li>
<p>Entraînement et réglagle du modèle</p>
</li>
<li>
<p>Choix du rendu (Data Viz ?)</p>
</li>
<li>
<p>Mise en conditions réelles</p>
</li>
</ul>
<h3>Difficultés rencontrées</h3>
<ul>
<li>
<p>Installation et paramètrage de CUDA</p>
</li>
<li>
<p>Compréhension des concepts clés (RNN, NLP, ...)</p>
</li>
<li>
<p>Choix du dataset (récupération brute est complexe mais un dataset kaggle parait simpliste)</p>
</li>
</ul>
<h2>Sprint 2</h2>
<ul>
<li>
<p>Choix du dataset [x]</p>
</li>
<li>
<p>Exploration et pre-processing (tokenisation et embedding) [x]</p>
</li>
<li>
<p>Entraînement des différents modèles [x]</p>
</li>
<li>
<p>Réglage des hyper-paramètres d'un modèle [x]</p>
</li>
<li>
<p>Implémentation de transfert learning [~]</p>
</li>
</ul>
<h3>Difficultés rencontrées</h3>
<ul>
<li>
<p>Impossibilité de pipeliner la démarche (spécifité des inputs pour les différents modèles)</p>
</li>
<li>
<p>Beaucoup de soucis de dimension entre les inputs et les outputs des différents modèles</p>
</li>
<li>
<p>&quot;Crash&quot; régulier de CUDA nécessitant de relancer l'entiereté du notebook</p>
</li>
</ul>
<h2>Travail réalisé</h2>
<p>Tout d'abord, il m'a été nécessaire d'installer les librairies suivantes :</p>
<pre class="language-sh " style="counter-reset: linenumber 0"><code class="language-sh">pip <span class="token function">install</span> transformers pandas nltk sklearn
</code></pre>
<p>Et pour cuda, l'installation s'est faite avec la commande suivante:</p>
<pre class="language-sh " style="counter-reset: linenumber 0"><code class="language-sh">pip3 <span class="token function">install</span> torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117
</code></pre>
<p>J'ai basé mon projet sur une base de données de 50k reviews IMDB, labellées &quot;positive&quot; ou &quot;negative&quot;, obtenue sur <a href="https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews">Kaggle</a></p>
<p>Au final, essayer de scraper des données sur le web, et surtout les labeler, aurait pris un temps monstrueux que je n'avais pas.</p>
<p>Le dataset était utilisable quasisement immédiatement et après un peud de data cleaning et de pre-processing, à savoir la tokenization. Je suis passé à l'entraînement de mes réseaux de neurone.</p>
<div class="quote relative  py-2 drop-shadow rounded rounded-tl-none rounded-bl-none border-solid border-l-8 border-cyan-500 bg-cyan-100">
<svg class="absolute w-7 h-7 pl-1 pt-0.5 pb-0.5 text-cyan-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
  <path stroke-linecap="round" stroke-linejoin="round" d="M9.663 17h4.673M12 3v1m6.364 1.636l-.707.707M21 12h-1M4 12H3m3.343-5.657l-.707-.707m2.828 9.9a5 5 0 117.072 0l-.548.547A3.374 3.374 0 0014 18.469V19a2 2 0 11-4 0v-.531c0-.895-.356-1.754-.988-2.386l-.548-.547z"></path>
</svg>
<div class="pl-8 mr-8">
<p>La <strong>tokenization</strong> est le processus de convertir du texte en une séquence de tokens qui sont des éléments individuels tels que des mots (en général), des phrases ou des symboles de ponctuation.. La tokenization est une étape fondamentale dans le traitement du langage naturel (NLP) car elle permet de transformer du texte brut en une représentation numérique que les modèles de NLP peuvent utiliser.</p>
</div></div>
<p>Une fois obtenu, il a fallu procéder à l'embedding (vectorisation numérique du vocabulaire constituant les tokens) de ces tokens pour qu'ils soit utilisable par mon réseau de neurones.</p>
<p>Tout d'abord, après avoir découvert PyTorch, j'ai essayé d'entraîner un réseau de neurones naïf que j'avais construit mais comme vous pouvez le voir, les résultats n'étaient pas très concluants.</p>
<p><img src="NaiveNetResults.png" alt="NaiveNetResults"></p>
<p>Je me suis renseigné davantage sur le domaine du NLP et j'ai appris qu'une architecture spécifique de réseau de neurones existait : les &quot;Recurrent Neural Network&quot; (RNN).</p>
<p>Un RNN est conçu pour prendre en compte les relations séquentielles entre les entrées, en stockant une mémoire interne qui leur permet de prendre en compte les entrées précédentes.</p>
<p><img src="rnn-vs-fnn.png" alt="Différence entre un RNN et un réseau classique"></p>
<p>Les avantages des RNN par rapport aux réseaux classiques incluent leur capacité à traiter des données séquentielles de longue durée, leur flexibilité en termes de taille d'entrée et leur capacité à prendre en compte les relations de dépendance temporelle dans les données.</p>
<p>Et les résultats étaient bien meilleurs:</p>
<p><img src="RNNetResults.png" alt="RNNetResults"></p>
<p>J'ai voulu alors voir si je pouvais améliorer ces résultats en réglant le taux d'apprentissage (hyper-paramètre clé dans l'étude de réseau de neurones.)</p>
<p><img src="LRcomparison.png" alt="LRcomparison"></p>
<p>Ensuite, avec le modèle RNN entrainé avec le meilleur LR, j'ai codé une fonction de prédiction de sentiment et j'ai tenté de piéger mon algorithme des phrases un peu sarcastiques</p>
<p><img src="sentiment_prediction.png" alt="Sentiment Prediction"></p>
<p>Enfin, j'ai entendu parlé de &quot;Transfer Learning&quot; vers la fin de mon POK. Il s'agit d'utiliser un réseau de neurone pré-entrainé, puis d'entraîner sa couche de classification sur notre problème spécifique.</p>
<p>J'ai essaié d'implémenter le modèle de Bert mais comme il fallait avoir recours à un tokenizer différent de celui que j'avais codé, je n'ai pas réussi à régler les problèmes de dimensions d'inputs.</p>


</article>

        </main>


        <footer class="min-h-[50px] border-t-2 border-gray-200 mt-4">
            <div class="max-w-[1000px] mx-auto px-4">
                <div class="min-h-[50px] flex justify-center items-center">
                    <p class="text-center">
                        <span style="font-family: Consolas, sans-serif;">Do_<span style="color: #4a86e8">It</span></span> : Développent et Organisation en IT
                    </p>
                </div>
            </div>
        </footer>

        <script>
        MathJax
            .startup
            .document
            .getMathItemsWithin(document.body);
        </script>

    </body>
</html>
